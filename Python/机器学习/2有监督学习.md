# 监督学习
1. 监督学习：利用一组带有标签的数据，学习从输入到输出的映射，然后将这种映射关系应用到位置数据上，达到==分类==或==回归==的目的。
    - 分类：当输出是离散的，学习任务为分类任务
    - 回归：当输出是连续的，学习任务为回归任务
2. 分类学习：
    - 输入：一组有标签的训练数据（观察或评估），标签表明了这些数据（观察）的所属类别
    - 输出：分类模型根据这些训练模型，训练自己的模型参数，学习出一个适合这组数据的分类器，当有新数据（非训练数据）需要进行类别判断，就可以将这组新数据作为输入放到选好的分类器进行判断。
    - 评价：
        - 训练集：用来训练模型的已标志数据，用来建立模型，发现规律。
        - 测试集：也是已标注数据，将标注隐藏，输送给训练好的模型，通过结果与真实标注进行对比，评估模型的学习能力。
        - 训练集和测试集的划分方法：根据已有标注数据，随机选出一部分(70%)数据作为训练数据，余下的作为测试数据，此外还有交叉验证法、自助法用于评估分类模型。
    - 评价指标：
        - **精确率**：针对==预测结果==而言，（以二分类为例）他表示的是预测为正的样本里有多少是真正的样本。（预测为正有两种情况：一种是把正预测为正TP，另一种是把负预测为正FP）
        ==P=(TP)/(TP+FP)==
        - **召回率**：针对==原来样本==而言，他表示的是样本中的正例有多少预测对了。（预测也有两种情况：一种是把原来的正预测为正TP，另一种是把原来的正预测为负FN）
        ==R=(TP)/(TP+FN)==
        - **准确率**：预测对的/所有
        ==A=(TP+TN)/(TP+TN+FN+FP)==
    - SKlearn vs. 分类
        - 与聚类算法被封装在sklearn.cluster模块不同，sklearn库中的分类算法并未被统一封装到一个子模块中，因此对分类算法的import方式各有不同。
        - SKlearn提供的分类函数有：（既有线性分类器，也有非线性分类器）
            - k近邻
            - 朴素贝叶斯
            - 支持向量机
            - 决策树
            - 神经网络模型等
3. 回归分析：
    - 回归：了解两个或多个变数间是否相关、研究其相关方向和强度，并建立数学模型以便观察特定变数来预测研究者感兴趣的变数。回归分析帮助人们了解在自变量变化时因变量的变化量。所有通过回归分析我们可以根据给出的自变量估计因变量的条件期望，
    - Sklearn VS. 回归
        - SKlearn提供的回归函数主要被封装在两个子模块中，分别是sklearn.linear_module和sklearn.preprocessing。sklearn.linear_module封装的是一些线性函数。
        - 线下回归函数：
            - 普通线性函数
            - 岭回归
            - Lasso
        - 非线性回归：多项式回归则通过调用sklearn.preprocessing子模块进行拟合。

---
## 一、分类
1. 人体运动状态预测——实例分析
---
## 二、回归
---
## 三、手写数字识别实例分析